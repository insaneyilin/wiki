<!DOCTYPE HTML>
<html>
  <head>
    <link rel="Stylesheet" type="text/css" href="/wiki/static/css/style.css">
    <link rel="Stylesheet" type="text/css" href="/wiki/static/css/tango.css">
    <link rel="shortcut icon" href="/wiki/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/wiki/favicon.ico" type="image/x-icon">
    <link rel="alternate" type="application/atom+xml" href="atom.xml" title="Atom feed">
    <title>自动驾驶技术概览 - Yilin's Wiki</title>
    <meta name="keywords" content=""/>
    <meta name="description" content=""/>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        extensions: ["tex2jax.js"],
        jax: ["input/TeX", "output/HTML-CSS"],
        tex2jax: {
          <!--$表示行内元素，$$表示块状元素 -->
          inlineMath: [ ['$','$'], ["\\(","\\)"] ],
          displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        "HTML-CSS": { availableFonts: ["TeX"] }
      });
    </script>
    <script type="text/javascript" async
      src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>

    <!--Mermaid流程图-->
    <script src="https://cdn.bootcss.com/mermaid/8.0.0-rc.8/mermaid.min.js"></script>
    <script>mermaid.initialize({startOnLoad:true});</script>
  </head>

  <body>
    <div id="container">
      
<div id="header">
  <div class="post-nav"><a href="/wiki/">Home</a>&nbsp;&#187;&nbsp;<a href="/wiki/#autonomous_driving">autonomous_driving</a>&nbsp;&#187;&nbsp;自动驾驶技术概览
    <span class="updated">Page Updated&nbsp;
      2019-07-27 00:52
    </span></div>
</div>
<div class="clearfix"></div>

<div class="page_title">自动驾驶技术概览</div>

  <div class="toc"><span class="toctitle">Table of Contents</span><ul>
<li><a href="#darpa">无人车的起源：DARPA</a></li>
<li><a href="#_1">自动驾驶分级</a></li>
<li><a href="#_2">自动驾驶中的传感器</a><ul>
<li><a href="#lidar">激光雷达 (LIDAR)</a></li>
<li><a href="#camera">摄像头 (Camera)</a></li>
<li><a href="#radar">Radar 等其他传感器</a></li>
<li><a href="#_3">多传感器融合</a></li>
</ul>
</li>
<li><a href="#_4">自动驾驶计算平台</a></li>
<li><a href="#_5">无人车成本</a></li>
<li><a href="#_6">自动驾驶技术拆解</a><ul>
<li><a href="#_7">宏观视角</a><ul>
<li><a href="#_8">感知</a></li>
<li><a href="#_9">高精地图</a></li>
<li><a href="#_10">路径规划</a></li>
<li><a href="#v2x">V2X</a></li>
<li><a href="#_11">定位</a></li>
<li><a href="#_12">规划与决策</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#_13">自动驾驶综述|定位、感知、规划常见算法</a><ul>
<li><a href="#_14">自动驾驶汽车系统结构概述</a></li>
<li><a href="#_15">感知模块</a><ul>
<li><a href="#_16">定位方法</a></li>
<li><a href="#_17">离线障碍物地图</a></li>
<li><a href="#_18">道路建模</a></li>
<li><a href="#_19">移动物体检测与跟踪</a></li>
<li><a href="#_20">交通信号检测与识别</a></li>
</ul>
</li>
<li><a href="#_21">决策模块</a><ul>
<li><a href="#route-planning">Route Planning</a></li>
<li><a href="#motion-planning">Motion Planning</a></li>
<li><a href="#control">Control</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<blockquote>
<p>自动驾驶汽车（AutomatedVehicle；Intelligent Vehicle；Autonomous Vehicle；Self-driving Car；Driverless Car）又称智能汽车、自主汽车、自动驾驶汽车或轮式移动机器人，是一种通过计算机实现自动驾驶的智能汽车。</p>
</blockquote>
<h2 id="darpa">无人车的起源：DARPA</h2>
<p>美国“神盾局”：美国国防高级研究计划局（Defense Advanced Research Projects Agency）。主攻“黑科技”的预研。</p>
<p>DARPA 部分成果：</p>
<ul>
<li>因特网（ARPANET, 1975）</li>
<li>卫星定位（Transit, 1960）</li>
</ul>
<p>DARPA超级挑战赛-2004</p>
<ul>
<li>240km荒漠行车，无人完成全程，最好的队伍只开了不到12km </li>
</ul>
<p>DARPA超级挑战赛-2005 </p>
<ul>
<li>212km荒漠行车，5支队伍完成全程，23支队伍超越2004最远距离 </li>
</ul>
<p>DARPA城市挑战赛-2007 </p>
<ul>
<li>96km城市路段，6支队伍完成全程，第一名仅用时4小时10分</li>
<li>3D激光雷达初露头角，大幅提高了自动驾驶的性能 </li>
<li>自动驾驶开始从理论预研转入应用，当年的参赛队员成为当前的自动驾驶行业中坚，DARPA预研重心转向自行走机器人</li>
</ul>
<h2 id="_1">自动驾驶分级</h2>
<p>NHTSA: 美国高速路安全管理局</p>
<p>SAE: 美国汽车工程师协会</p>
<p>NHTSA 的 L4 对应着 SAE 里的 L4+L5</p>
<p>目前常用 SAE 的 L0~L5 分级。</p>
<h2 id="_2">自动驾驶中的传感器</h2>
<h3 id="lidar">激光雷达 (LIDAR)</h3>
<p>3D 激光雷达特点：</p>
<ul>
<li>大角度或 360 度全景扫描，可直接构建周围环境的三维深度信息</li>
<li>可在各种光照条件下使用（包括夜间） </li>
<li>大致可分为机械旋转扫描和固态扫描两种类型</li>
</ul>
<p>3D 激光雷达缺点：</p>
<ul>
<li>分辨率受限，通常无法获得对象的颜色信息</li>
<li>雪、雾天气会使感知距离下降，雨水烟雾会导致检测盲区</li>
<li>（机械旋转式）激光雷达结构精密，量产困难，可靠性待提升</li>
</ul>
<h3 id="camera">摄像头 (Camera)</h3>
<p>制造技术成熟，成本低廉。</p>
<p>单目摄像头：</p>
<ul>
<li>丰富的颜色、纹理信息，符合人类视觉感知特点</li>
<li>由于二维图像映射三维的误差，单目测距精度有限</li>
<li>视野取决于镜头：长焦看得远，但视野窄；短焦视野广，但看不远</li>
<li>雨、雪、雾天气和镜头有污点时识别性能会下降</li>
<li>除红外摄像头外，不能在夜间使用</li>
</ul>
<p>双目摄像头：</p>
<ul>
<li>通过双个摄像头之间的图像差异来构建三维信息（双目视觉技术）</li>
<li>有效视角比单目摄像头窄</li>
<li>有效视距低于激光雷达（其视距取决于两个摄像头之间的距离(基线)：距离小时远处的场景立体感太小，距离大时又难于获取近处的三维场景）</li>
</ul>
<p>多目摄像头：</p>
<ul>
<li>多目摄像头，可以通过不同的摄像头来覆盖不同范围的场景，既解决了摄像头无法来回切换焦距的问题，也可以一次性解决不同距离下识别清晰度的问题。</li>
<li>e.g. 广角镜头用来看近处的环境，80度的覆盖30米左右的环境，60度覆盖中远距离，40度负责远距离观察。不同的摄像头负责观察不同距离、角度范围的场景，各司其职，互不干扰。</li>
<li>难点：安装方案，算法配合，计算开销</li>
</ul>
<h3 id="radar">Radar 等其他传感器</h3>
<p>毫米波雷达：</p>
<ul>
<li>性价比高，车规级产品量产容易</li>
<li>探测距离远于激光雷达</li>
<li>缺点：数据稳定性差，毫米波发出的电磁波对金属极为敏感</li>
</ul>
<p>超声波雷达：</p>
<ul>
<li>常见的倒车雷达就是超声波雷达</li>
<li>通常作用范围3米以内，角度分辨率很低</li>
<li>通常只能给出探测距离，无法精确描述障碍物的位置</li>
</ul>
<p>2D 激光雷达：</p>
<ul>
<li>通常可扫描1-4个平面，水平分辨率很高</li>
</ul>
<h3 id="_3">多传感器融合</h3>
<ul>
<li>单一传感器无法覆盖全部测量场景需求<ul>
<li>远/近距离使用，贴地物体检测，速度测量，测量分辨率</li>
<li>雨、雪、雾天气，夜间使用</li>
</ul>
</li>
<li>基于单一传感器的识别性能不佳<ul>
<li>摄像头分割/检测三维物体难，激光雷达单帧分辨率低</li>
</ul>
</li>
<li>多传感器融合是趋势，利用多个传感器信息融合，冗余、互补，提高综合感知能力</li>
</ul>
<h2 id="_4">自动驾驶计算平台</h2>
<p>NVIDIA Drive PX2</p>
<ul>
<li>全自动驾驶计算平台</li>
<li>12个最高性能64位ARM核心</li>
<li>2个最新桌面级GPU核</li>
<li>最新的16 nm工艺 </li>
<li>250W功耗，需要专门的液态冷却系统来完成散热</li>
<li>相当于 150 个 Macbook pro （2016年）</li>
</ul>
<p>Mobileye EyeQ3</p>
<ul>
<li>ADAS 计算平台</li>
<li>4个MIPS CPU 核心，性能大约相当于2010年左右的ARM内核</li>
<li>4个运算加速核，总处理能力大致相当于1台MacBook</li>
<li>2.5W功耗</li>
</ul>
<p>Mobileye EyeQ4</p>
<ul>
<li>ADAS 计算平台</li>
<li>14 个计算核心，其中10个为特制矢量加速器，大幅提升了视觉处理和数据解读的性能</li>
<li>四个CPU处理器内核，每个内核又拥有四个硬件线程，性能超过EyeQ2和EyeQ3使用的创新型向量微码六核处理器（VMP）</li>
</ul>
<p>Mobileye EyeQ5 （2020）</p>
<ul>
<li>超低功耗，对标全自动驾驶计算平台</li>
</ul>
<h2 id="_5">无人车成本</h2>
<p>2016 年数据</p>
<p>激光雷达</p>
<ul>
<li>未来预期价格：\$90-\$8000</li>
<li>价格波动因素：2D/3D，机械扫描/固态扫描等不同技术方向是价格差异的主要原因</li>
</ul>
<p>摄像头</p>
<ul>
<li>单目：\$125-\$150</li>
<li>双目：\$150-\$200</li>
</ul>
<p>毫米波雷达</p>
<ul>
<li>长距：\$125-\$150</li>
<li>短距：\$50-\$100</li>
</ul>
<p>车载计算平台</p>
<ul>
<li>传感器总成本的 50% -- 200%</li>
</ul>
<p>超声波雷达</p>
<ul>
<li>\$15-\$20</li>
</ul>
<p>里程计</p>
<ul>
<li>\$80-\$120</li>
</ul>
<p>DGPS</p>
<ul>
<li>\$80 -- \$6000</li>
<li>价格波动因素：DGPS技术（伪距差分/RTK），是否集成惯性导航单元IMU</li>
</ul>
<hr />
<h2 id="_6">自动驾驶技术拆解</h2>
<h3 id="_7">宏观视角</h3>
<div class="hlcode"><pre><span></span><span class="err">感知外界环境</span> <span class="o">-&gt;</span> <span class="err">映射汽车视角</span> <span class="o">-&gt;</span> <span class="err">驾驶汽车决策</span>
</pre></div>


<ul>
<li>感知外界环境<ul>
<li>路线规划：我要去哪，哪里能走</li>
<li>地图：路在哪里，限速吗</li>
<li>车载感知：附近有什么障碍物</li>
</ul>
</li>
<li>映射汽车视角<ul>
<li>车观视角：无人车看到的环境是什么样的</li>
<li>本车定位：无人车自身在什么地方</li>
</ul>
</li>
<li>驾驶汽车决策<ul>
<li>行车策略</li>
<li>轨迹规划</li>
<li>轨迹执行</li>
</ul>
</li>
</ul>
<h4 id="_8">感知</h4>
<p>感知技术的三个层面（由低到高） </p>
<ul>
<li>能避让行车方向的障碍物：碰撞预警（半自动驾驶） </li>
<li>能在空无一人的道路上开车：车道位置/交通信息牌/红绿灯感知</li>
<li>能在有行人车辆的道路上开车：运动物体的感知</li>
</ul>
<p>感知技术难点</p>
<ul>
<li>交通场景中物体类别繁多，检测难</li>
<li>同时跟踪场景中多个障碍物，需要保证实时性</li>
<li>训练数据收集、标注难</li>
<li>考虑传感器成本，技术方案选择</li>
</ul>
<h4 id="_9">高精地图</h4>
<p>自动驾驶中使用高精地图的意义</p>
<ul>
<li>为高精定位提供参照物坐标 <ul>
<li>在地图中预先标记特定物体（如电线杆）的精确坐标，通过测算车辆与其之间的距离来推算本车坐标 </li>
</ul>
</li>
<li>记录已知环境，提升环境感知的总体准确率 <ul>
<li>高精地图对静态环境（车道线、护栏、路牌信息等）提供高可靠性描述，可降低现场识别的难度，提升总体准确率性 </li>
</ul>
</li>
<li>归一索引行车记录，作为大数据训练的基础 <ul>
<li>为持续训练自动驾驶算法，需要对不同车次的实际行车数据（本车轨迹、其它车辆行人的运动等）进行归一化记录 </li>
<li>在高精地图建立的三维空间上映射车辆位置，是对齐不同车次数据记录的最佳方式，精确度最高</li>
</ul>
</li>
</ul>
<h4 id="_10">路径规划</h4>
<p>路线规划是已经成熟的地图技术，例子：百度地图</p>
<h4 id="v2x">V2X</h4>
<p>Vehicle To Everything</p>
<ul>
<li>车车通信（V2V）和车与基础设施通讯（V2I）的总称</li>
<li>例子<ul>
<li>向车辆报告前方拥堵状况；向调度中心报告本车位置</li>
<li>向车辆报告前方红绿灯状态</li>
<li>通过第三方后台，汇总道路上所有车辆的实时位置</li>
</ul>
</li>
<li>在基础设施建设完备前，V2X 无法可靠地帮助自动驾驶</li>
</ul>
<h4 id="_11">定位</h4>
<p>两种定位方式：全局定位和相对定位。</p>
<p>全局定位</p>
<ul>
<li>DGPS(Differential-GPS)：通过地面基站信号校正GPS精度，在不依赖地图信息的情况下获取车辆绝对坐标</li>
<li>IMU(Inertial Measurement Unit)：记录车辆的加速度、角速度信息，推算其距离上次精准定位后的位移，作为DGPS的补充</li>
</ul>
<p>相对定位</p>
<ul>
<li>SLAM(Simultaneous  Localization and Mapping): 测量车辆与多个已知坐标的参照物之间的距离，从而计算出车辆的坐标</li>
</ul>
<p>稳定的定位输出需要两种定位技术的融合。</p>
<p>全局定位技术无法提供精度稳定的输出 </p>
<ul>
<li>DGPS信号接收易受干扰，不稳定 </li>
<li>IMU只能缓解DGPS的不稳定问题，但无法根除</li>
</ul>
<p>相对定位+全局定位的技术被业界广泛使用。</p>
<h4 id="_12">规划与决策</h4>
<p>车辆驾驶可分为行车策略、轨迹规划、轨迹执行三个步骤</p>
<ul>
<li>行车策略(Maneuver Planning)决定汽车将要采取的行动<ul>
<li>直行跟随还是并线超车？是否要转弯？ </li>
</ul>
</li>
<li>轨迹规划(Trajectory Planning)为汽车的行动规划合适的轨迹<ul>
<li>轨迹尽量平滑，尽量远离所有障碍物，高速时不应急转弯等</li>
</ul>
</li>
<li>轨迹执行(Trajectory Execution)控制实际轨迹<ul>
<li>尽量减小实际轨迹与规划轨迹间的误差</li>
</ul>
</li>
</ul>
<p>行车策略是自动驾驶的核心</p>
<ul>
<li>是否具有行车策略能力，是全自动驾驶与半自动驾驶的主要区别</li>
<li>良好的车载感知性能，是开展行车策略研究的前提</li>
<li>车辆/行人的运动预测（Motion Planning），选取什么模型（RL，有监督？）</li>
<li>道路行驶场景的归纳和穷举（路测+仿真模拟）</li>
</ul>
<p>轨迹规划是一个几何曲线的动态规划问题</p>
<ul>
<li>选择合理的几何模型，生成一组平滑的备选轨迹<ul>
<li>贝塞尔函数、回旋曲线函数、纳尔逊多项式、样条函数等</li>
</ul>
</li>
<li>建立代价函数(cost function)，优选轨迹<ul>
<li>代价函数要素：障碍物位置、运动趋势、车辆操控性能</li>
</ul>
</li>
<li>轨迹规划输出要素<ul>
<li>轨迹曲线，车身姿态、转向角、转向角速度，是否需要加减速</li>
</ul>
</li>
</ul>
<p>轨迹执行</p>
<ul>
<li>需要良好的控制回路：位置、速度、加速度多环反馈+前馈</li>
<li>精确、实时的车辆状态监测</li>
</ul>
<p>现阶段，感知算法是自动驾驶的最大瓶颈，其次是行车策略。(2019)</p>
<hr />
<hr />
<h2 id="_13">自动驾驶综述|定位、感知、规划常见算法</h2>
<p>整理自<a href="https://mp.weixin.qq.com/s?__biz=MzU1MjY4MTA1MQ==&amp;mid=2247487803&amp;idx=1&amp;sn=59ec87d45a35037b735b6f79532fcf8e&amp;chksm=fbff3a0fcc88b3195ad691a431fb8bd6019a38a5e5bfeebd93844e663e2eba38ee99ee49fb49&amp;mpshare=1&amp;scene=1&amp;srcid=0508YcUb1emOBKIYjvGYtW5g&amp;sharer_sharetime=1588900444048&amp;sharer_shareid=c0d8d647194ca8d8e74a6f38874f41b2&amp;exportkey=AWoi1WPE647G%2Fv7BnGWoes8%3D&amp;pass_ticket=%2FfsLdT%2BkaMm1dxYkA01aDwUAfR0baNIRPg00%2BpWK1wdzHbiL7L3bW7BxAKQH4LQV#rd">自动驾驶综述|定位、感知、规划常见算法汇总</a></p>
<h3 id="_14">自动驾驶汽车系统结构概述</h3>
<p>自动驾驶感知和决策功能划分：</p>
<ul>
<li>感知系统<ul>
<li>定位</li>
<li>静态障碍物检测</li>
<li>移动障碍物检测与跟踪</li>
<li>道路检测</li>
<li>交通信号检测与识别</li>
<li>...</li>
</ul>
</li>
<li>决策系统<ul>
<li>路径规划</li>
<li>行为选择</li>
<li>运动规划和控制</li>
<li>...</li>
</ul>
</li>
</ul>
<p><strong>决策系统</strong>：</p>
<ul>
<li>负责将汽车从初始位置导航到用户定义的最终目标（A to B），考虑车辆状态、外部环境、交通规则和乘客的舒适度；</li>
<li>决策系统需要知道汽车在环境中的位置。</li>
</ul>
<p><strong>定位模块</strong>：</p>
<ul>
<li>根据环境的静态地图（高精地图、定位地图、语义地图...）估计车辆定位状态（姿态、线速度、角速度等）；</li>
<li>静态地图预先制作完成，通常使用自动驾驶汽车自身的传感器，需要人工标注（人行横道或红绿灯的位置）或编辑（移除传感器捕获的非静态物体）。</li>
<li>定位模块接收离线地图、传感器数据和平台里程计作为输入，生成自动驾驶汽车的状态作为输出</li>
<li>自动驾驶仅使用 GPS 在城市环境中进行定位不够可靠（树木、建筑物、隧道等造成的干扰）</li>
</ul>
<p><strong>行为选择器（Behavior Selector）模块</strong>：</p>
<ul>
<li>负责选择当前的驾驶行为，如车道保持、交叉口处理、红绿灯处理等；</li>
<li>根据当前驾驶行为选择目标，并在决策时间范围内避免与环境中的静态和移动障碍物发生碰撞</li>
</ul>
<p><strong>运动规划模块</strong>：</p>
<ul>
<li>负责计算从当前车辆状态到当前目标的轨迹，该轨迹遵循行为选择器定义的路径，满足车辆的运动学和动力学约束，并为乘客提供舒适性。</li>
</ul>
<h3 id="_15">感知模块</h3>
<h4 id="_16">定位方法</h4>
<ul>
<li>基于激光雷达的定位</li>
<li>基于激光雷达+相机定位</li>
<li>基于相机的定位</li>
</ul>
<h4 id="_17">离线障碍物地图</h4>
<ul>
<li>静态障碍物地图</li>
<li>该子系统对于允许自主车辆在公共道路上安全行驶而不与障碍物（如路标、路缘）碰撞至关重要</li>
<li>区分自由（可穿越）空间和占用空间。</li>
<li>由地图绘制阶段的传感器数据构建，并存储在自主操作阶段供以后使用。</li>
</ul>
<h4 id="_18">道路建模</h4>
<ul>
<li>收集周围道路和车道的信息，并将其表示在具有几何和拓扑特性的地图中，包括相互连接和限制。</li>
<li>如何进行地图表示和地图创建</li>
<li>网格地图，拓扑地图</li>
<li>人工标注，自动标注</li>
</ul>
<h4 id="_19">移动物体检测与跟踪</h4>
<ul>
<li>MOT，Multiple Object Tracking，这里的含义包括了检测与跟踪</li>
<li>提供动态障碍物检测能力</li>
<li>该子系统对于使自主车辆做出决策和避免与 <strong>潜在移动物体</strong> （如其他车辆和行人）碰撞至关重要。</li>
<li>通常针对传感器测量的不确定性，采用Bayes滤波器（如Kalman和粒子滤波器）进行状态预测。</li>
</ul>
<p>传统(Traditional) MOT：</p>
<ul>
<li>数据分割</li>
<li>数据关联</li>
<li>状态估计（滤波）</li>
</ul>
<p>Model Based MOT：</p>
<ul>
<li>直接从传感器数据中推断，使用传感器的物理模型和对象的几何模型，并使用非参数滤波器（如粒子滤波器）；</li>
<li>不需要数据分割和关联步骤，因为几何对象模型将数据关联到目标</li>
</ul>
<p>Stereo Vision Based MOT：</p>
<ul>
<li>e.g. Stixels 障碍物检测与跟踪</li>
</ul>
<p>Grid Map Based MOT：</p>
<ul>
<li>首先构建动态环境的占用栅格地图</li>
<li>地图构建步骤之后是数据分割、数据关联和过滤步骤，以便提供场景的对象级表示</li>
<li>基于相关的三维点估计网格地图中每个单元的占用概率</li>
<li>使用基于八叉树的3D局部占用栅格地图，该地图将环境划分为占用、自由和未知体素</li>
<li>在构建局部网格地图后，基于局部网格地图中自由空间和占用空间的不一致性，可以检测出移动障碍物。动态体素被聚集成移动的物体，这些物体被进一步划分成层。</li>
</ul>
<p>Sensor Fusion Based MOT：</p>
<ul>
<li>融合来自各种传感器（如激光雷达、雷达和照相机）的数据，以探索它们各自的特点，提高环境感知能力</li>
<li>前融合，后融合</li>
</ul>
<p>Deep Learning Based MOT：</p>
<ul>
<li>利用深度神经网络检测运动障碍物的位置和几何特征</li>
<li>End to End，同时给出检测和跟踪结果</li>
</ul>
<h4 id="_20">交通信号检测与识别</h4>
<ul>
<li>负责对交通规则中定义的标志进行检测和识别，使车辆能够根据交通规律做出正确的决策</li>
<li>交通灯、交通标志和自动驾驶汽车周围环境中的路面标记</li>
</ul>
<p>Traffic Light Detection and Recognition：</p>
<ul>
<li>基于模型的方法，早期的交通灯检测和识别方法大多是基于模型的，依赖于手工制设计的特征工程，利用人类掌握的关于物体颜色和形状的信息来建立一个能够检测和/或识别物体的模型，普遍存在大量的超参数；</li>
<li>基于深度学习的方法，端到端检测或者检测+分类；</li>
</ul>
<p>Traffic Sign Detection and Recognition：</p>
<ul>
<li>和红绿灯类似，基于模型 -&gt; 基于学习</li>
</ul>
<p>Pavement Marking Detection and Recognition：</p>
<ul>
<li>路面标线检测与识别包括检测路面标线的位置并识别其类型（如车道标线、道路标线、信息和人行横道）。</li>
<li>辅助进行行人检测</li>
</ul>
<h3 id="_21">决策模块</h3>
<h4 id="route-planning">Route Planning</h4>
<ul>
<li>路径规划（叫路线更合适，强调 global，全局性；注意和 motion planning 中的 path planning 作区分）</li>
<li>负责计算从自驾车的初始位置到用户操作员定义的最终位置之间通过道路网络的路线</li>
<li>如果用一个加权有向图来表示道路网，其边权表示通过一个路段的代价，那么计算一条路线的问题就可以归结为在加权有向图中寻找最短路径的问题</li>
<li>对于大型道路网络，经典的最短路径算法，如 Dijkstra 和 A star 的复杂度是不切实际的</li>
<li>对于大型道路网络，经典的最短路径算法，如Dijkstra和A*的复杂度是不切实际的</li>
<li>道路网中的路径规划方法在查询时间、预处理时间、空间利用率和对输入变化的鲁棒性等方面提供了不同的权衡。它们主要可分为四类：goal-directed, separator-based, hierarchical, bounded-hop.</li>
</ul>
<p>Goal-Directed Techniques：</p>
<ul>
<li>通过避免扫描不在目标顶点方向上的顶点来引导从源顶点到目标顶点的搜索</li>
<li>A star 是一种经典的目标导向最短路径算法。与Dijkstra算法相比，该算法在每个顶点上使用一个较低的距离函数，从而使更接近目标的顶点更早地被扫描，从而获得更好的性能。</li>
<li>ALT（A star、地标和三角形不等式）算法</li>
<li>arc flags方法</li>
</ul>
<p>Separator-Based Techniques：</p>
<ul>
<li>基于分隔符的技术基于顶点或边分隔符。</li>
<li>顶点（或边）分隔符是顶点（或边）的一个小子集，其移除将图分解为几个平衡的单元。基于顶点分隔符的算法使用顶点分隔符来计算覆盖图。</li>
<li>快捷边将添加到覆盖图中，以便保留与完整图的任何顶点对之间的距离。</li>
<li>覆盖图比完整图小得多，用于加速查询算法。</li>
</ul>
<p>Hierarchical Techniques：</p>
<ul>
<li>利用了道路网络固有的层次结构，其中主要道路（如公路）组成一个小的干线子网。一旦源顶点和目标顶点距离较远，查询算法只扫描子网的顶点。</li>
</ul>
<p>Bounded-Hop Techniques：</p>
<ul>
<li>通过向图中添加虚拟快捷方式来预计算顶点对之间的距离。由于预先计算所有顶点对之间的距离对于大型网络是不可行的，因此有界跳技术的目标是在跳数很少的情况下获得任何虚拟路径的长度。</li>
</ul>
<p>Combinations:</p>
<ul>
<li>将上述各种技术组合到利用不同图形特性的混合算法中</li>
</ul>
<h4 id="motion-planning">Motion Planning</h4>
<ul>
<li>负责计算从自动驾驶汽车的当前状态到行为选择子系统定义的下一个局部目标状态的路径或轨迹。</li>
<li>执行局部驾驶行为，满足汽车的运动学和动力学约束，为乘客提供舒适性，避免与环境中的静态和移动障碍物发生碰撞。</li>
<li>规划结果可以是路径或轨迹。路径是汽车状态的序列，它不定义汽车状态如何随时间演变。此任务可委托给其他子系统（如行为选择子系统）或速度剖面可定义为曲率和接近障碍物的函数。轨迹是一条指定汽车状态随时间演化的路径。</li>
</ul>
<p>Path Planning：</p>
<ul>
<li>包括从汽车当前状态到下一个目标状态生成一系列状态，这并不定义汽车状态随时间的演变。</li>
<li>通常分为全局和局部路径规划。在全局路径规划中，在车辆开始移动之前，使用环境的脱机全局地图计算全局路径。在局部路径规划中，当汽车行驶时，利用周围环境的在线局部地图生成局部路径，使汽车能够处理行驶中的障碍物。（全局路径规划应该就是上面的 route planning）</li>
<li>路径规划的方法主要分为两类：基于图搜索的和基于插值曲线的方法。</li>
</ul>
<p>轨迹规划：</p>
<ul>
<li>包括从自动驾驶汽车的当前状态到下一个目标状态的序列生成，该序列指定汽车状态随时间的演变。</li>
<li>轨迹规划方法主要分为四类：基于图搜索的、基于采样的、基于插值曲线的和基于数值优化的方法。</li>
</ul>
<h4 id="control">Control</h4>
<p>在自动驾驶汽车领域，控制是指工程领域自动控制背后的理论，它涵盖了在没有持续的直接人为干预的情况下，应用各种机制来操作和调节过程。在最简单的自动控制类型中，控制子系统将过程的输出与期望的输入进行比较，并使用误差（过程的输出与期望的输入之间的差异）来改变过程的输入，从而使过程在受到干扰的情况下保持在其设定点。</p>
    </div>
    <div id="footer">
      <span>
        <p>Copyright © 2020 Yilin Gui.
        Powered by <a href="http://simiki.org/" target="_blank">Simiki</a>.</p>
        <p>Site Generated 2020-06-29 09:26:16</p>
      </span>
    </div>

    
    
  </body>
</html>